{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accepting Class details:\n",
    "import datetime\n",
    "\n",
    "year = str(input(\"Enter year: \"))\n",
    "stream = str(input(\"Enter stream (CSE/IT): \"))\n",
    "course = str(input(\"Enter course (BTech or MTech): \"))\n",
    "subjectCode = str(input(\"Enter Subject Code: \"))\n",
    "subjectName = str(input(\"Enter Subject Name: \"))\n",
    "subjectCredits = str(input(\"Enter Subject Credits: \"))\n",
    "teacher = str(input(\"Enter Teacher Name: \"))\n",
    "timestamp = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import db, credentials, storage\n",
    "\n",
    "cred_obj = firebase_admin.credentials.Certificate('secret key.json')\n",
    "default_app = firebase_admin.initialize_app(cred_obj, {\n",
    "\t'databaseURL': \"https://smartattend-6da73-default-rtdb.firebaseio.com/\",\n",
    "    'storageBucket': 'smartattend-6da73.appspot.com'\n",
    "})\n",
    "\n",
    "# Get a database reference to our posts\n",
    "ref = db.reference('Attendance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "students = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucket = storage.bucket()\n",
    "# blob = bucket.get_blob(f'user_photos/2020/BTech/CSE/07901012020/face_photo')\n",
    "# arr = np.frombuffer(blob.download_as_string(), np.uint8)\n",
    "# img = cv2.imdecode(arr, cv2.COLOR_BGR2BGR555)\n",
    "# cv2.imshow('image', img)\n",
    "# print(img)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = storage.bucket()\n",
    "list_blobs = list(bucket.list_blobs(prefix = f'user_photos/{year}/{course}/{stream}/'))\n",
    "\n",
    "for blob_class in list_blobs:\n",
    "    blob_name = blob_class.name\n",
    "    if blob_name.endswith('face_photo'):\n",
    "        blob = bucket.get_blob(blob_name)\n",
    "        arr = np.frombuffer(blob.download_as_string(), np.uint8)\n",
    "        img = cv2.imdecode(arr, cv2.COLOR_BGR2BGR555)\n",
    "        # cv2.imshow('image', img)\n",
    "        students[blob_name] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_photos/2020/BTech/CSE/07301012020/face_photo': array([[[254, 254, 254],\n",
      "        [254, 254, 254],\n",
      "        [254, 254, 254],\n",
      "        ...,\n",
      "        [242, 244, 244],\n",
      "        [243, 245, 245],\n",
      "        [243, 245, 245]],\n",
      "\n",
      "       [[254, 254, 254],\n",
      "        [254, 254, 254],\n",
      "        [254, 254, 254],\n",
      "        ...,\n",
      "        [242, 244, 244],\n",
      "        [243, 245, 245],\n",
      "        [243, 245, 245]],\n",
      "\n",
      "       [[253, 253, 253],\n",
      "        [253, 253, 253],\n",
      "        [253, 253, 253],\n",
      "        ...,\n",
      "        [242, 244, 244],\n",
      "        [243, 245, 245],\n",
      "        [243, 245, 245]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 93,  78, 162],\n",
      "        [ 93,  78, 162],\n",
      "        [ 94,  79, 163],\n",
      "        ...,\n",
      "        [ 41,  26,  94],\n",
      "        [ 40,  26,  90],\n",
      "        [ 37,  23,  87]],\n",
      "\n",
      "       [[ 91,  80, 152],\n",
      "        [ 91,  80, 152],\n",
      "        [ 92,  81, 153],\n",
      "        ...,\n",
      "        [ 42,  31,  87],\n",
      "        [ 41,  29,  81],\n",
      "        [ 39,  27,  79]],\n",
      "\n",
      "       [[ 49,  42,  99],\n",
      "        [ 49,  42,  99],\n",
      "        [ 50,  43, 100],\n",
      "        ...,\n",
      "        [ 22,  15,  58],\n",
      "        [ 24,  16,  56],\n",
      "        [ 22,  14,  54]]], dtype=uint8), 'user_photos/2020/BTech/CSE/07901012020/face_photo': array([[[131, 169, 199],\n",
      "        [130, 168, 198],\n",
      "        [129, 168, 196],\n",
      "        ...,\n",
      "        [ 97, 138, 153],\n",
      "        [ 97, 137, 155],\n",
      "        [ 96, 136, 155]],\n",
      "\n",
      "       [[132, 168, 198],\n",
      "        [131, 167, 197],\n",
      "        [131, 168, 196],\n",
      "        ...,\n",
      "        [ 93, 141, 153],\n",
      "        [ 93, 140, 154],\n",
      "        [ 95, 138, 157]],\n",
      "\n",
      "       [[132, 168, 198],\n",
      "        [131, 167, 197],\n",
      "        [131, 168, 196],\n",
      "        ...,\n",
      "        [ 91, 141, 153],\n",
      "        [ 91, 140, 154],\n",
      "        [ 93, 139, 157]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[104, 144, 162],\n",
      "        [109, 147, 165],\n",
      "        [115, 154, 169],\n",
      "        ...,\n",
      "        [107, 151, 168],\n",
      "        [117, 160, 175],\n",
      "        [114, 163, 173]],\n",
      "\n",
      "       [[104, 141, 161],\n",
      "        [106, 144, 162],\n",
      "        [110, 146, 162],\n",
      "        ...,\n",
      "        [115, 158, 177],\n",
      "        [118, 162, 179],\n",
      "        [117, 161, 178]],\n",
      "\n",
      "       [[105, 142, 162],\n",
      "        [104, 142, 160],\n",
      "        [103, 142, 157],\n",
      "        ...,\n",
      "        [114, 160, 178],\n",
      "        [119, 162, 181],\n",
      "        [118, 161, 180]]], dtype=uint8)}\n"
     ]
    }
   ],
   "source": [
    "print(students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "frame_count = camera.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "fps = camera.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "output = cv2.VideoWriter('./Video.avi', cv2.VideoWriter_fourcc(*'MJPG'), fps, (640, 480))\n",
    "\n",
    "if not camera.isOpened():\n",
    "    print(\"Error in opening camera\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    frame_count += 1\n",
    "    if int(frame_count//fps) >= 3:\n",
    "        break\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    ret, frame = camera.read()\n",
    "    cv2.imshow('Capturing Video', frame)\n",
    "    output.write(frame)\n",
    "\n",
    "camera.release()\n",
    "output.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video started\n"
     ]
    }
   ],
   "source": [
    "video = cv2.VideoCapture('./Video.avi')\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "frame_count = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "number_of_frames_required = 15\n",
    "seconds = frame_count/(fps*number_of_frames_required)\n",
    "print('video started')\n",
    "\n",
    "for extracted_frame in range(number_of_frames_required):\n",
    "    frame_id = int(fps*seconds*extracted_frame)\n",
    "    video.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
    "    ret, frame = video.read()\n",
    "    cv2.waitKey(0)\n",
    "    cv2.imwrite(\"./frames/\" + str(extracted_frame) + \".png\", frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_number_of_heads = 10000\n",
    "max_number_of_heads = 0\n",
    "cropped = 0\n",
    "\n",
    "for frame_number in range(number_of_frames_required):\n",
    "    frame = cv2.imread('./frames/' + str(frame_number) + '.png')\n",
    "    grayscale_image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_alt.xml') \n",
    "    detected_faces = face_cascade.detectMultiScale(grayscale_image)\n",
    "    min_number_of_heads = min(min_number_of_heads, len(detected_faces))\n",
    "    max_number_of_heads = max(max_number_of_heads, len(detected_faces))\n",
    "    for (column, row, width, height) in detected_faces:\n",
    "        # cv2.rectangle(frame,(column, row),(column + width, row + height),(0, 255, 0),4)\n",
    "        cv2.imwrite(\"./refined-images/\" + str(cropped) + \".png\", frame[row:row+height, column:column+width])\n",
    "        cropped += 1\n",
    "    # plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    # plt.axis(\"off\")\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Students in the class are: 1\n"
     ]
    }
   ],
   "source": [
    "# HEAD COUNT\n",
    "if min_number_of_heads == max_number_of_heads:\n",
    "    print('Number of Students in the class are: ' + str(min_number_of_heads))\n",
    "else:\n",
    "    print(\"Number of Students in the class are within the range: \" + str(min_number_of_heads) + '-' + str(max_number_of_heads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attendance is: \n",
      "['07301012020']\n"
     ]
    }
   ],
   "source": [
    "present = []\n",
    "\n",
    "for cropped_img in range(cropped):\n",
    "    for key in students:\n",
    "        rollnumber = key.removeprefix(f'user_photos/{year}/{course}/{stream}/')[0:11]\n",
    "        student_img = students[key]\n",
    "        if(rollnumber not in present):\n",
    "            try:\n",
    "                result = DeepFace.verify(img1_path = \"./refined-images/\" + str(cropped_img) + \".png\", img2_path = student_img)\n",
    "                if (result['verified'] == True):\n",
    "                    present.append(rollnumber)\n",
    "            except:\n",
    "                result = False\n",
    "\n",
    "print(\"Attendance is: \")\n",
    "print(present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "attendance_ref = ref.child(f'{course}/{stream}/{year}/{teacher}/{subjectCode} {subjectName} {subjectCredits}/')\n",
    "\n",
    "# Updating the number of classes held\n",
    "try:\n",
    "    totalClassesHeld = int(ref.get()[course][stream][year][subject]['totalClassesHeld'])+1\n",
    "    print(totalClassesHeld)\n",
    "    attendance_ref.update({\n",
    "        'totalClassesHeld': str(totalClassesHeld)\n",
    "    })\n",
    "except:\n",
    "    attendance_ref.update({\n",
    "        'totalClassesHeld': 1\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for student in present:\n",
    "    attendance_ref.push().set({\n",
    "        'enrollmentNumber': student,\n",
    "        'timestamp': str(timestamp)\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
