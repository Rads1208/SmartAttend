{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Taking Video Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "frame_count = camera.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "fps = camera.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "output = cv2.VideoWriter('./Video.avi', cv2.VideoWriter_fourcc(*'MJPG'), fps, (640, 480))\n",
    "\n",
    "if not camera.isOpened():\n",
    "    print(\"Error in opening camera\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    frame_count += 1\n",
    "    if int(frame_count//fps) >= 3:\n",
    "        break\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    ret, frame = camera.read()\n",
    "    cv2.imshow('Capturing Video', frame)\n",
    "    output.write(frame)\n",
    "\n",
    "camera.release()\n",
    "output.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Frame Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture('./Video.avi')\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "frame_count = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "number_of_frames_required = 15\n",
    "seconds = frame_count/(fps*number_of_frames_required)\n",
    "print('video started')\n",
    "\n",
    "for extracted_frame in range(number_of_frames_required):\n",
    "    frame_id = int(fps*seconds*extracted_frame)\n",
    "    video.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
    "    ret, frame = video.read()\n",
    "    cv2.waitKey(0)\n",
    "    cv2.imwrite(\"./frames/\" + str(extracted_frame) + \".png\", frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 and 4: Face Detection, Head Count and Image Refinement\n",
    "### Implementation of Viola Jones Algorithm\n",
    "This document contains the basic implementation of the Viola-Jones algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_number_of_heads = 10000\n",
    "max_number_of_heads = 0\n",
    "cropped = 0\n",
    "\n",
    "for frame_number in range(number_of_frames_required):\n",
    "    frame = cv2.imread('./frames/' + str(frame_number) + '.png')\n",
    "    grayscale_image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_alt.xml') \n",
    "    detected_faces = face_cascade.detectMultiScale(grayscale_image)\n",
    "    min_number_of_heads = min(min_number_of_heads, len(detected_faces))\n",
    "    max_number_of_heads = max(max_number_of_heads, len(detected_faces))\n",
    "    for (column, row, width, height) in detected_faces:\n",
    "        # cv2.rectangle(frame,(column, row),(column + width, row + height),(0, 255, 0),4)\n",
    "        cv2.imwrite(\"./refined-images/\" + str(cropped) + \".png\", frame[row:row+height, column:column+width])\n",
    "        cropped += 1\n",
    "    # plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    # plt.axis(\"off\")\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HEAD COUNT\n",
    "if min_number_of_heads == max_number_of_heads:\n",
    "    print('Number of Students in the class are: ' + str(min_number_of_heads))\n",
    "else:\n",
    "    print(\"Number of Students in the class are within the range: \" + str(min_number_of_heads) + '-' + str(max_number_of_heads))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs = DeepFace.find(img_path = \"face1.png\", db_path = \"./database/\")\n",
    "# print(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = DeepFace.verify(img1_path = \"face1.png\", img2_path = \"./database/0.png\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cropped_img in range(cropped):\n",
    "#     try:\n",
    "#         result = DeepFace.verify(img1_path = \"./refined-images/\" + str(cropped_img) + \".png\", img2_path = \"./database/0.png\")\n",
    "#     except:\n",
    "#         result = \"false\"\n",
    "#     print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "present = []\n",
    "\n",
    "for cropped_img in range(cropped):\n",
    "    for filename in os.listdir(\"./tmp\"):\n",
    "        rollnumber = str(filename).split(\".\")[0]\n",
    "        if(rollnumber not in present):\n",
    "            try:\n",
    "                result = DeepFace.verify(img1_path = \"./refined-images/\" + str(cropped_img) + \".png\", img2_path = \"./tmp/\" + str(filename))\n",
    "                if (result['verified'] == True):\n",
    "                    present.append(rollnumber)\n",
    "            except:\n",
    "                result = False\n",
    "\n",
    "print(\"Attendance is: \")\n",
    "print(present)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Step: Accepting Class Details and Posting data to Firebase Realtime Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accepting Class details:\n",
    "import datetime\n",
    "\n",
    "year = str(input(\"Enter year: \"))\n",
    "stream = \"CSE\"\n",
    "course = str(input(\"Enter course (BTech or MTech)\"))\n",
    "subject = str(input(\"Enter Subject Code\"))\n",
    "timestamp = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import db\n",
    "\n",
    "cred_obj = firebase_admin.credentials.Certificate('secret key.json')\n",
    "default_app = firebase_admin.initialize_app(cred_obj, {\n",
    "\t'databaseURL': \"https://smartattend-6da73-default-rtdb.firebaseio.com/\"\n",
    "})\n",
    "\n",
    "# Get a database reference to our posts\n",
    "ref = db.reference('Attendance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Posting Data to Firebase Realtime database\n",
    "# import requests\n",
    "# path = f'https://smartattend-6da73-default-rtdb.firebaseio.com/Attendance/{course}/{stream}/{year}/{subject}'\n",
    "# # print(path)\n",
    "# requests.post(path, data='{\"words/banana\":true, \"words/pie\":true}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attendance_ref = ref.child(f'{course}/{stream}/{year}/{subject}/')\n",
    "\n",
    "# Updating the number of classes held\n",
    "try:\n",
    "    totalClassesHeld = int(ref.get()[course][stream][year][subject]['totalClassesHeld'])+1\n",
    "    print(totalClassesHeld)\n",
    "    attendance_ref.update({\n",
    "        'totalClassesHeld': str(totalClassesHeld)\n",
    "    })\n",
    "except:\n",
    "    attendance_ref.update({\n",
    "        'totalClassesHeld': 1\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for student in present:\n",
    "    attendance_ref.push().set({\n",
    "        'enrollmentNumber': student,\n",
    "        'timestamp': str(timestamp)\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
